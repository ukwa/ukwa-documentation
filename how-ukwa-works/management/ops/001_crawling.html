
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Crawler Operations &#8212; UKWA Technical Documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Setting up a AWS Cloud server for the Domain Crawl" href="010_crawler_setup_aws_dc.html" />
    <link rel="prev" title="Operations" href="../op_act.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      <img src="../../../_static/ukwa-2018-onwhite-close.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">UKWA Technical Documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Using the UK Web Archive
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../using-ukwa-services/index.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../opendata/_index.html">
   Datasets
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../opendata/ukwa.ds.1/_index.html">
     UK Selective Web Archive
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../opendata/ukwa.ds.1/classification/index.html">
       UK Selective Web Archive Classification Dataset
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../opendata/ukwa.ds.2/_index.html">
     JISC UK Web Domain Dataset
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../opendata/ukwa.ds.2/cdx/index.html">
       Crawled URL Index
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../opendata/ukwa.ds.2/fmt/index.html">
       Format Profile
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../opendata/ukwa.ds.2/geo/index.html">
       Geoindex
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../opendata/ukwa.ds.2/linkage/index.html">
       Links by Domain Suffix
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../../opendata/ukwa.ds.2/host-linkage/index.html">
       Host Link Graph
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  How UKWA Works
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../_index.html">
   Goals &amp; Principles
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../arch/overview.html">
   Technical Architecture
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/ingest.html">
     Ingest Services
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/manage.html">
     Management Services
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../arch/access.html">
     Access Services
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../_index.html">
   Management
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../op_act.html">
     Operations
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Crawler Operations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="010_crawler_setup_aws_dc.html">
       Setting up a AWS Cloud server for the Domain Crawl
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../op_response.html">
     Runbooks
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../runbooks/001_cdx_outage.html">
       Switching over to the secondary CDX service
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Run Your Own Web Archives
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../make-your-own-warcs/index.html">
   Make your own WARCs
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../use-your-warcs/index.html">
   Use Your WARCs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../use-your-warcs/analysis.html">
     Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../use-your-warcs/integration.html">
     Integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../use-your-warcs/playback.html">
     Playback
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../use-your-warcs/search.html">
     Search
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/how-ukwa-works/management/ops/001_crawling.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ukwa/ukwa-documentation"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ukwa/ukwa-documentation/issues/new?title=Issue%20on%20page%20%2Fhow-ukwa-works/management/ops/001_crawling.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/ukwa/ukwa-documentation/edit/master/content/how-ukwa-works/management/ops/001_crawling.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-test-this-documentation">
     How to test this documentation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pre-requisites">
   Pre-requisites
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#checking-service-status">
     Checking Service Status
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cleaning-up">
     Cleaning Up
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reviewing-the-deployment-configuration">
   Reviewing the Deployment Configuration
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#launching-the-kafka-stack">
   Launching the Kafka stack
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#launching-the-crawler-stack">
   Launching the Crawler stack
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crawl-jobs">
   Crawl Jobs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#starting-crawl-jobs">
   Starting Crawl Jobs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unpausing-crawl-job-s">
   Unpausing crawl job(s)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#monitoring-crawl-jobs">
   Monitoring Crawl Jobs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stopping-crawl-jobs">
   Stopping Crawl Jobs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pause-the-crawl-job-s">
   Pause the crawl job(s)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checkpoint-the-job-s">
   Checkpoint the job(s)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stop-the-crawl-job-s">
   Stop the Crawl Job(s)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shut-down-the-crawl-services">
   Shut down the Crawl Services
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="crawler-operations">
<h1>Crawler Operations<a class="headerlink" href="#crawler-operations" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>This page describes how to a manage our crawl services and jobs. This applies to all crawl jobs:</p>
<ul class="simple">
<li><p>The Domain Crawl (<code class="docutils literal notranslate"><span class="pre">dc</span></code>)</p></li>
<li><p>The Frequent Crawls (<code class="docutils literal notranslate"><span class="pre">fc</span></code>) which consist of two different crawls (NPLD <code class="docutils literal notranslate"><span class="pre">npld</span></code> and By-Permission <code class="docutils literal notranslate"><span class="pre">bypm</span></code>)</p></li>
</ul>
<div class="section" id="how-to-test-this-documentation">
<h3>How to test this documentation<a class="headerlink" href="#how-to-test-this-documentation" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="https://github.com/ukwa/ukwa-heritrix">ukwa-heritrix</a> repository contains the source code for our crawler, and also comes with a Docker Compose file so the whole thing can be spun up locally.  This is a very close match for the Frequent Crawl system can be used to try out the operations shown below. See the <a class="reference external" href="https://github.com/ukwa/ukwa-heritrix#readme">ukwa-heritrix README on GitHub</a> for more details.</p>
<p>One notable difference between the development version and the production version is that production does not use a single Docker Compose file with everything in it. Intead we use two separate Compose files that are deployed as Docker Swarm Stacks: one for the Kafka subsystem and another for the actual crawler itself.</p>
</div>
</div>
<div class="section" id="pre-requisites">
<h2>Pre-requisites<a class="headerlink" href="#pre-requisites" title="Permalink to this headline">¶</a></h2>
<p>This page assumes that a suitable host server has already been set up, with sufficient disk space, and with Docker Swarm installed. To meet NPLD requirements, the server must have direct internet access, and use a public IP address that is registered under a domain name that makes it clear who we are.  This means setting up the DNS records so that site owners can look up who we are based on the IP address alone ( IP =&gt; hostname ).</p>
<p>For further details, see:</p>
<ul class="simple">
<li><p><em>TBA: Link to local crawler setup</em></p></li>
<li><p><span class="xref myst">AWS Domain Crawl Setup</span></p></li>
</ul>
<div class="section" id="checking-service-status">
<h3>Checking Service Status<a class="headerlink" href="#checking-service-status" title="Permalink to this headline">¶</a></h3>
<p>You can check if any stacks are currently deployed using:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker stack ls
</pre></div>
</div>
<p>And check the services for a stack with (e.g.):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker stack ps fc_kafka
</pre></div>
</div>
<p>You should check you understand the current status of the services before you proceed. For example, if you just rebooted the server, then all the services will come up automatically, but you’ll still have to wait for Kafka before launching a crawl (see below).</p>
<p>If the state of the system cannot be made clear, the simplest thing is to start afresh:</p>
<ol class="simple">
<li><p>as per instructions below, remove all running Docker Stacks.</p></li>
<li><p>reboot the server.</p></li>
</ol>
<p>The system will then come back with no live services, and you may launch them as described below, and resume the relevant crawls as appropriate.</p>
</div>
<div class="section" id="cleaning-up">
<h3>Cleaning Up<a class="headerlink" href="#cleaning-up" title="Permalink to this headline">¶</a></h3>
<p>Note that before doing any service changes, it is often helpful to clear out any information associated with services that are no longer running. e.g. this avoids confusion when inspecting the logs of services.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker system prune -f
</pre></div>
</div>
</div>
</div>
<div class="section" id="reviewing-the-deployment-configuration">
<h2>Reviewing the Deployment Configuration<a class="headerlink" href="#reviewing-the-deployment-configuration" title="Permalink to this headline">¶</a></h2>
<p><em>TBA: VARS</em></p>
</div>
<div class="section" id="launching-the-kafka-stack">
<h2>Launching the Kafka stack<a class="headerlink" href="#launching-the-kafka-stack" title="Permalink to this headline">¶</a></h2>
<p>The current crawl engine is integrated with <em>Apache Kafka</em>, and so this service needs be started before Heritrix.  This means the <code class="docutils literal notranslate"><span class="pre">fc_kafka</span></code> and <code class="docutils literal notranslate"><span class="pre">dc_kafka</span></code> stacks for the frequent and domain crawls respectively. These configurations are available at <a class="reference external" href="https://github.com/ukwa/ukwa-services/tree/master/ingest/fc/fc-kafka">fc-kafka</a>, <a class="reference external" href="https://github.com/ukwa/ukwa-services/tree/master/ingest/dc/dc-kafka">dc-kafka</a>.</p>
<div class="figure align-center" id="fc-kafka-stack">
<a class="reference internal image-reference" href="../../../_images/fc_kafka.svg"><img alt="../../../_images/fc_kafka.svg" height="500px" src="../../../_images/fc_kafka.svg" /></a>
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">A visualiation of the main components of the <code class="docutils literal notranslate"><span class="pre">fc_kafka</span></code> Docker Stack configuration.</span><a class="headerlink" href="#fc-kafka-stack" title="Permalink to this image">¶</a></p>
</div>
<p>To deploy the Kafka service stack. e.g. for <code class="docutils literal notranslate"><span class="pre">dc</span></code>:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd ingest/dc/dc-kafka
./deploy-kafka-prod.sh
</pre></div>
</div>
<p>We can then check what’s happening either using:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker service ps --no-trunc dc_kafka_kafka_1

docker service logs --tail 100 -f dc_kafka_kafka_1
</pre></div>
</div>
<p>If the Kafka instance is brand new, it will be up and running very quickly. However, if this is any kind of restart, Kafka can take quite some time to start up, with regular logging like this:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>...Loading producer state from snapshot files...
</pre></div>
</div>
<p>Once it’s checked all the partitions of the topics it contains, the logging should settle down. You can also check this by looking at the <em>Trifecta</em> user interface, which should be accessible on port 9000 of the crawling machine.  Note that it does tend to get confused if it is accessed before Kafka is ready. In this case, it’ll need to be restarted, like this:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker service update --force dc_kafka_ui
</pre></div>
</div>
</div>
<div class="section" id="launching-the-crawler-stack">
<h2>Launching the Crawler stack<a class="headerlink" href="#launching-the-crawler-stack" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">fc_crawl</span></code> and <code class="docutils literal notranslate"><span class="pre">dc_crawl</span></code> stack definitions can be found at <a class="reference external" href="https://github.com/ukwa/ukwa-services/tree/master/ingest/fc/fc-crawl">fc-crawl</a>, <a class="reference external" href="https://github.com/ukwa/ukwa-services/tree/master/ingest/dc/dc-crawl">dc-crawl</a>.</p>
<div class="figure align-center" id="fc-crawk-stack">
<a class="reference internal image-reference" href="../../../_images/fc_crawl.svg"><img alt="../../../_images/fc_crawl.svg" height="500px" src="../../../_images/fc_crawl.svg" /></a>
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">A visualiation of the main components of the <code class="docutils literal notranslate"><span class="pre">fc_crawl</span></code> Docker Stack configuration.</span><a class="headerlink" href="#fc-crawk-stack" title="Permalink to this image">¶</a></p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">fc_crawl</span></code> stack is the more complex than the <code class="docutils literal notranslate"><span class="pre">dc</span></code> equivalent, as it includes the components needed to render some web pages using a web browser behind an archiving proxy (<code class="docutils literal notranslate"><span class="pre">warcprox</span></code>).  There are also some differences in how the crawls are configured. The details of the Heritrix configuration are described in <em>TBA</em>.</p>
<p><em>TBC</em></p>
<ul class="simple">
<li><p>Check surts and exclusions.</p></li>
<li><p>Check GeoIP DB (GeoLite2-City.mmdb) is installed and up to date.</p></li>
<li><p>JE cleaner threads</p></li>
<li><p>je.cleaner.threads to 16 (from the default of 1) - note large numbers went very badly causing memory exhaustion</p></li>
<li><p>Bloom filter</p></li>
<li><p>MAX_RETRIES=4</p></li>
</ul>
</div>
<div class="section" id="crawl-jobs">
<h2>Crawl Jobs<a class="headerlink" href="#crawl-jobs" title="Permalink to this headline">¶</a></h2>
<p>The current crawl engine relies on Heritrix3 state management to keep track of crawl state, and this was not designed to cope under un-supervised system restarts. i.e. rather than being stateless, or delegating state management to something that ensures the live state is preserved immediately, we need to manage ensuring the runtime state is recorded on disk. This is why crawler operations are more complex than other areas.</p>
<p>Specifically, when running long crawls, operational managment of Heritrix tends to focus on managing crawl state and the <em>checkpoints</em> that preserve the state of the crawl frontier so that crawls can be resumed if needed.</p>
<p>Note that as well as the domain crawl, we run two Heritrix ‘frequent crawl’ services, one for NPLD content and one for by-permission crawling. When performing a full stop of the frequent crawls, both services need to be dealt with cleanly.</p>
<table class="colwidths-auto table" id="crawls-table">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Crawls and Service Endpoints. These are only accessible from UKWA networks and by UKWA staff.</span><a class="headerlink" href="#crawls-table" title="Permalink to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Crawl</p></th>
<th class="head"><p>Heritrix Service</p></th>
<th class="head"><p>Kafka UI</p></th>
<th class="head"><p>Prometheus</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Frequent NPLD</p></td>
<td><p><a class="reference external" href="https://crawler06.bl.uk:8443/">https://crawler06.bl.uk:8443/</a></p></td>
<td><p><a class="reference external" href="https://crawler06.bl.uk:9000/">https://crawler06.bl.uk:9000/</a></p></td>
<td><p><a class="reference external" href="https://crawler06.bl.uk:9191/">https://crawler06.bl.uk:9191/</a></p></td>
</tr>
<tr class="row-odd"><td><p>Frequent By-Permission</p></td>
<td><p><a class="reference external" href="https://crawler06.bl.uk:9443/">https://crawler06.bl.uk:9443/</a></p></td>
<td><p><em>as above</em></p></td>
<td><p><em>as above</em></p></td>
</tr>
<tr class="row-even"><td><p>Domain</p></td>
<td><p><a class="reference external" href="https://crawler07.bl.uk:8443/">https://crawler07.bl.uk:8443/</a></p></td>
<td><p><a class="reference external" href="https://crawler07.bl.uk:9000/">https://crawler07.bl.uk:9000/</a></p></td>
<td><p><a class="reference external" href="https://crawler07.bl.uk:9191/">https://crawler07.bl.uk:9191/</a></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="starting-crawl-jobs">
<h2>Starting Crawl Jobs<a class="headerlink" href="#starting-crawl-jobs" title="Permalink to this headline">¶</a></h2>
<p>Crawl jobs are started via the Heritrix service. Every UKWA Heritrix service has a job called <code class="docutils literal notranslate"><span class="pre">frequent</span></code> that is used to perform the crawl for that instance of Heritrix, e.g. <a class="reference external" href="https://crawler06.bl.uk:8443/engine/job/frequent">https://crawler06.bl.uk:8443/engine/job/frequent</a> for the Frequent NPLD crawl.</p>
<p>Visiting those pages, we see that the job is <code class="docutils literal notranslate"><span class="pre">Unbuilt</span></code>, so the first thing to do is use the <code class="docutils literal notranslate"><span class="pre">BUILD</span></code> action to set up the job. This takes the configuration file known as ‘crawler beans’ and uses it to generate a set of live Java objects that will run the crawl. If all goes well, the job should then report as <code class="docutils literal notranslate"><span class="pre">Ready</span></code>.</p>
<p>At this point, we can either launch a new job, or launch from a chosen checkpoint. In general, we want to resume a crawl, so we pick the checkpoint with the most recent timestamp and click <code class="docutils literal notranslate"><span class="pre">LAUNCH</span></code>.  If expected checkpoints are not present, this means something went wrong while writing them. This should be reported to try to determine and address the root cause, but there’s not much to be done other than select the most recent valid checkpoint.  If no recent checkpoints are valid, or if we want to clear out the space, or if we’re making a significant change to how the crawler works, then we’ll have to start afresh.</p>
<p>While the launch/resume process is happening, the crawler will report as <code class="docutils literal notranslate"><span class="pre">PREPARING</span></code>. Once that’s done, the crawl will either immediately start crawling (i.e. straight into the <code class="docutils literal notranslate"><span class="pre">RUNNING</span></code> state), or launch into the <code class="docutils literal notranslate"><span class="pre">PAUSED</span></code> state. This depends on the Heritrix configuration, and in general we let the frequent crawls start running immediately, but start the domain crawls in <code class="docutils literal notranslate"><span class="pre">PAUSED</span></code> state so we can keep a closer eye on things.</p>
<ul class="simple">
<li><p>Unbuilt -&gt; Ready</p></li>
<li><p>Active: PREPARING, RUNNING, EMPTY, PAUSING PAUSED, STOPPING, Finished/ABORTED</p></li>
</ul>
</div>
<div class="section" id="unpausing-crawl-job-s">
<span id="crawl-op-unpause"></span><h2>Unpausing crawl job(s)<a class="headerlink" href="#unpausing-crawl-job-s" title="Permalink to this headline">¶</a></h2>
<p>When the crawler is in the <code class="docutils literal notranslate"><span class="pre">PAUSED</span></code> state, just click the <code class="docutils literal notranslate"><span class="pre">UNPAUSE</span></code> button to begin or resume a crawl.</p>
</div>
<div class="section" id="monitoring-crawl-jobs">
<h2>Monitoring Crawl Jobs<a class="headerlink" href="#monitoring-crawl-jobs" title="Permalink to this headline">¶</a></h2>
<p>When the crawl is running happily, the Heritrix job page should report a reasonable number of URI/s processed. Usually at least 10 URI/s, but peaking in the hundreds for larger crawls.</p>
<p>Every crawl stack includes an embedded Prometheus instance that gathers crawl metrics and makes them available for direct assessment and federated aggregation into our production Prometheus monitoring service.</p>
</div>
<div class="section" id="stopping-crawl-jobs">
<h2>Stopping Crawl Jobs<a class="headerlink" href="#stopping-crawl-jobs" title="Permalink to this headline">¶</a></h2>
<p>If possible, we wish to preserve the current state of the crawl, so we try to pause and cleanly shut down while making a checkpoint to restart from.</p>
</div>
<div class="section" id="pause-the-crawl-job-s">
<span id="crawl-op-pause"></span><h2>Pause the crawl job(s)<a class="headerlink" href="#pause-the-crawl-job-s" title="Permalink to this headline">¶</a></h2>
<p>For all Heritrixes in the Docker Stack: log into the Heritrix3 control UI, and pause any job(s) on the crawler that are in the <code class="docutils literal notranslate"><span class="pre">RUNNING</span></code> state. After the <code class="docutils literal notranslate"><span class="pre">PAUSE</span></code> button is pressed, the crawl enters the <code class="docutils literal notranslate"><span class="pre">PAUSING</span></code> state, while it waits for various threads to shutdown neatly. This can take a while (say up to two hours) if a given <code class="docutils literal notranslate"><span class="pre">ToeThread</span></code> is doing something like processing many thousands of discovered URLs from a site map.  If all goes well, all <code class="docutils literal notranslate"><span class="pre">RUNNING</span></code> jobs will eventually go from <code class="docutils literal notranslate"><span class="pre">PAUSING</span></code> to <code class="docutils literal notranslate"><span class="pre">PAUSED</span></code>.</p>
<p>Sometimes pausing never completes because of some bug. For example, under some cirumstances a <code class="docutils literal notranslate"><span class="pre">ToeThread</span></code> can die due to a run time error, and after that happens, and attempt to pause will get stuck in the <code class="docutils literal notranslate"><span class="pre">PAUSING</span></code> state.</p>
<p>If the crawler is being paused due to a temporary network outage, it doesn’t matter if the crawler is <code class="docutils literal notranslate"><span class="pre">PAUSING</span></code> rather than <code class="docutils literal notranslate"><span class="pre">PAUSED</span></code>. In either case, we can go ahead and <a class="reference internal" href="#crawl-op-unpause"><span class="std std-ref">unpause</span></a> when the outage is over.  However, it does not hurt to take this opportunity to checkpoint each crawl job, in case something goes wrong while we’re <code class="docutils literal notranslate"><span class="pre">PAUSING/PAUSED</span></code>.</p>
<p>However, if some critical component is down (like a disk drive or remote service like the crawl-time CDX index), then the <code class="docutils literal notranslate"><span class="pre">ToeThreads</span></code> may all get stuck trying to shut down. If this happens, there’s not a lot we can do except accept shut down and accept that we may need to restart from an older checkpoint.</p>
</div>
<div class="section" id="checkpoint-the-job-s">
<h2>Checkpoint the job(s)<a class="headerlink" href="#checkpoint-the-job-s" title="Permalink to this headline">¶</a></h2>
<p>Via the UI, request a checkpoint. If there’s not been one for a while, this can be quite slow (tens of minutes). If it works, a banner should flash up with the checkpoint ID, which should be noted so the crawl can be resumed from the right checkpoint. If the checkpointing fails, the logs will need to be checked for errors, as unless a new checkpoint is succefully completed, it will likely not be valid.</p>
<p>As an example, under some circumstances the log rotation does not work correctly. This means non-timestamped log files may be missing, which means when the next checkpoint runs, there are errors like:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ docker logs --tail 100 fc_crawl_npld-heritrix-worker.1.h21137sr8l31niwsx3m3o7jri
....
SEVERE: org.archive.crawler.framework.CheckpointService checkpointFailed  Checkpoint failed [Wed May 19 12:47:13 GMT 2021]
java.io.IOException: Unable to move /heritrix/output/frequent-npld/20210424211346/logs/runtime-errors.log to /heritrix/output/frequent-npld/20210424211346/logs/runtime-erro
rs.log.cp00025-20210519124709
</pre></div>
</div>
<p>These errors can be avoided by adding empty files in the right place, e.g.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>touch /mnt/gluster/fc/heritrix/output/frequent-npld/20210424211346/logs/runtime-errors.log
</pre></div>
</div>
<p>But immediately re-attempting to checkpoint a paused crawl will usually fail with:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Checkpoint not made -- perhaps no progress since last? (see logs)
</pre></div>
</div>
<p>This is because the system will not attempt a new checkpoint if the crawl state has not changed. Therefore, to force a new checkpoint, it is necessary to briefly un-pause the crawl so some progress is made, then re-pause and re-checkpoint.</p>
</div>
<div class="section" id="stop-the-crawl-job-s">
<h2>Stop the Crawl Job(s)<a class="headerlink" href="#stop-the-crawl-job-s" title="Permalink to this headline">¶</a></h2>
<p>At this point, all activity should have stopped, so it should not make much difference how exactly the service is halted.  To attempt to keep things as clean as possible, first terminate the job. The status should go to <code class="docutils literal notranslate"><span class="pre">STOPPING</span></code> and then to <code class="docutils literal notranslate"><span class="pre">ABORTED</span></code>, although in some cases the system can get stuck in <code class="docutils literal notranslate"><span class="pre">STOPPING</span></code>. If that happens, give it about ten minutes and then proceed to teardown the job(s) via the Heritrix UI.</p>
<p>You can now shut down the services at the Docker level.</p>
</div>
<div class="section" id="shut-down-the-crawl-services">
<h2>Shut down the Crawl Services<a class="headerlink" href="#shut-down-the-crawl-services" title="Permalink to this headline">¶</a></h2>
<p>First, remove the crawl stack, e.g. for the frequent crawl:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker stack rm fc_crawl
</pre></div>
</div>
<p>or for the domain crawl:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker stack rm dc_crawl
</pre></div>
</div>
<p>The Heritrix containers are configured to give themselves a few minutes to shut down neatly.  If this is unnecessary, the container can be killed directly using <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">rm</span> <span class="pre">&lt;container.id&gt;</span></code> .</p>
<p>Then shut down Kafka</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker stack rm fc_kafka
</pre></div>
</div>
<p>or</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker stack rm dc_kafka
</pre></div>
</div>
<p>If Docker actions are not responsive, it may be necessary to restart Docker itself. This means all the services get restarted with the current deployment configuration.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>service docker restart
</pre></div>
</div>
<p>Even this can be quite slow sometimes, so be patient.</p>
<p>If all else fails, force a reboot.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./how-ukwa-works/management/ops"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../op_act.html" title="previous page">Operations</a>
    <a class='right-next' id="next-link" href="010_crawler_setup_aws_dc.html" title="next page">Setting up a AWS Cloud server for the Domain Crawl</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The UK Web Archive<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>